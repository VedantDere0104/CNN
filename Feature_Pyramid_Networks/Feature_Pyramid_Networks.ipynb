{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature_Pyramid_Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw9tDUwSVjLM"
      },
      "source": [
        "####"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5lG8NaGVmei"
      },
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NROKVrkJWvDV"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7XKzKNzVoLw"
      },
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels, \n",
        "                 out_channels , \n",
        "                 kernel_size = (3 , 3) , \n",
        "                 stride = (1 , 1) , \n",
        "                 padding = 1 , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True ,\n",
        "                 use_pool = False):\n",
        "        super(Conv , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "        self.use_pool = use_pool\n",
        "        self.conv1 = nn.Conv2d(in_channels , \n",
        "                               out_channels , \n",
        "                               kernel_size , \n",
        "                               stride , \n",
        "                               padding)\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.InstanceNorm2d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.activation = nn.LeakyReLU(0.2)\n",
        "        if self.use_pool:\n",
        "            self.maxpool = nn.MaxPool2d(kernel_size=2 , stride=2)\n",
        "\n",
        "    def forward(self ,x ):\n",
        "        x = self.conv1(x)\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.activation(x)\n",
        "        if self.use_pool:\n",
        "            x = self.maxpool(x)\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYp-zDtTWdHy",
        "outputId": "c878a17a-3394-484d-e81c-f60b4b12df31"
      },
      "source": [
        "x = torch.randn(2 , 3 , 512 , 512).to(device)\n",
        "conv = Conv(3 , 32 , use_pool=True).to(device)\n",
        "z = conv(x)\n",
        "z.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 32, 256, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URiiASr8ejYj"
      },
      "source": [
        "class ConvT(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 kernel_size = (2 , 2) , \n",
        "                 stride = (2 , 2) , \n",
        "                 padding = 0 , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True):\n",
        "        super(ConvT , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "\n",
        "        self.convT1 = nn.ConvTranspose2d(in_channels , \n",
        "                                         out_channels , \n",
        "                                         kernel_size , \n",
        "                                         stride , \n",
        "                                         padding)\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.InstanceNorm2d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.activation = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.convT1(x)\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtkcCiQwfMqE",
        "outputId": "0a9e3035-ddf2-408a-a058-e75b6a76710b"
      },
      "source": [
        "x = torch.randn(2 , 3 , 512 , 512).to(device)\n",
        "convT = ConvT(3 , 32).to(device)\n",
        "z = convT(x)\n",
        "z.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 32, 1024, 1024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwGdFOcMW7Co"
      },
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True):\n",
        "        super(Linear , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "\n",
        "        self.linear1 = nn.Linear(in_channels , \n",
        "                                 out_channels)\n",
        "\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.BatchNorm1d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.activation = nn.LeakyReLU(0.2)\n",
        "            \n",
        "    def forward(self , x):\n",
        "        x = self.linear1(x)\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EtQfL93Xcu5",
        "outputId": "858ed8a5-80a2-46cc-a317-53d5d7812c83"
      },
      "source": [
        "x = torch.randn(2 , 512).to(device)\n",
        "linear = Linear(512 , 256).to(device)\n",
        "z = linear(x)\n",
        "z.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6HU6Ffck8-Y"
      },
      "source": [
        "class M_Block(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels_cls = 20 , \n",
        "                 out_channels_bbox = 4):\n",
        "        super(M_Block , self).__init__()\n",
        "\n",
        "        self.conv1 = Conv(in_channels , \n",
        "                          in_channels)\n",
        "        self.conv_cls = Conv(in_channels , \n",
        "                             out_channels_cls ,\n",
        "                             kernel_size = (1 , 1) ,\n",
        "                             stride = (1 ,1) , \n",
        "                             padding = 0)\n",
        "        self.conv_bbox = Conv(in_channels , \n",
        "                              out_channels_bbox , \n",
        "                              kernel_size = (1 ,1) , \n",
        "                              stride = (1 , 1) , \n",
        "                              padding = 0)\n",
        "        \n",
        "    def forward(self , x):\n",
        "        x = self.conv1(x)\n",
        "        x_cls = self.conv_cls(x)\n",
        "        x_bbox = self.conv_bbox(x)\n",
        "        return x_cls , x_bbox"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu3JA8O1llys"
      },
      "source": [
        "x = torch.randn(2 , 16 , 128 , 128).to(device)\n",
        "m = M_Block(16).to(device)\n",
        "x_cls , z_bbox = m(x)\n",
        "x_cls.shape , z_bbox.shape"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLl72Z8MYTMu"
      },
      "source": [
        "config = [\n",
        "          # out_channels , kernel_size , stride , padding , use_norm , use_activation , use_pool\n",
        "          # S for save\n",
        "          [16 , (3 , 3) , (1 , 1) , 1 , True , True , True] , # 16 x 256 x 256\n",
        "          [32 , (3 , 3) , (1 , 1) , 1 , True , True , True] , # 32 x 128 x 128\n",
        "          [64 , (3 , 3) , (1 , 1) , 1 , True , True , True] , # 64 x 64 x 64\n",
        "          [128 , (3 , 3) , (1 , 1) , 1 , True , True , True] ,# 128 x 32 x 32\n",
        "          [256 , (3 , 3) , (1 , 1) , 1 , True , True , True] ,# 256 x 16 x 16 \n",
        "\n",
        "          [128 , (1 , 1) , (1 , 1) , 0 , True , True , False] ,# 128 x 16 x 16 \n",
        "          128 , \n",
        "          'U' ,  # 128 x 32 x 32  \n",
        "          [64 , (1 , 1) , (1 , 1) , 0 , True , True , False] ,  # 64 x 32 x 32\n",
        "          64 , \n",
        "          'U' , # 64 x 64 x 64\n",
        "          [32 , (1 , 1) , (1 , 1) , 0 , True , True , False] ,  # 32 x 64 x 64\n",
        "          32 , \n",
        "          'U' , # 32 x 128 x 128\n",
        "          [16 , (1 , 1) , (1 , 1) , 0 , True , True , False] ,  # 16 x 128 x 128\n",
        "          16 , \n",
        "          'U' # 16 x 256 x 256\n",
        "]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trO0X9pCct1V"
      },
      "source": [
        "class FPN(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 config = config):\n",
        "        super(FPN , self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for layer in config:\n",
        "            if isinstance(layer , list):\n",
        "                out_channels , kernel_size , stride , padding , use_norm , use_activation , use_pool = layer\n",
        "                self.layers.append(Conv(\n",
        "                    in_channels , \n",
        "                    out_channels , \n",
        "                    kernel_size , \n",
        "                    stride , \n",
        "                    padding , \n",
        "                    use_norm , \n",
        "                    use_activation , \n",
        "                    use_pool\n",
        "                ))\n",
        "                in_channels = out_channels\n",
        "            elif isinstance(layer , str):\n",
        "                if layer == 'U':\n",
        "                    self.layers.append(nn.Upsample(scale_factor=2))\n",
        "            elif isinstance(layer , int):\n",
        "                in_channels_out = layer\n",
        "                self.layers.append(M_Block(in_channels_out))\n",
        "\n",
        "    def forward(self , x):\n",
        "        for_concat = []\n",
        "        output = []\n",
        "        for i , layer in enumerate(self.layers):\n",
        "            if isinstance(layer , Conv) or isinstance(layer , nn.Upsample):\n",
        "                x = layer(x)\n",
        "                if i != 0 and isinstance(layer , Conv):\n",
        "                    for_concat.append(x)\n",
        "            else:\n",
        "                if isinstance(layer , M_Block):\n",
        "                    output_ = self.layers[i](x)\n",
        "                    output.append(output_)\n",
        "                    last_ = for_concat.pop()\n",
        "                    x = x + last_\n",
        "        return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ewchjLknFAV"
      },
      "source": [
        "x = torch.randn(2 , 3 , 512 , 512).to(device)\n",
        "fpn = FPN(3).to(device)\n",
        "z = fpn(x)\n",
        "len(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4VwsD5WT_cg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}