{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNet_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVRGyQZNGklx"
      },
      "source": [
        "####"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL70mPoxGnyq"
      },
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8WIztN-I5Kr"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctZ1MJ2hGp3g"
      },
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 kernel_size = (3 , 3) , \n",
        "                 stride = (1 , 1) , \n",
        "                 padding = 1 , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True , \n",
        "                 use_grps = False):\n",
        "        super(Conv , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "        \n",
        "        groups = out_channels if use_grps else 1\n",
        "        self.conv1 = nn.Conv2d(in_channels , \n",
        "                               out_channels , \n",
        "                               kernel_size , \n",
        "                               stride , \n",
        "                               padding , \n",
        "                               groups = groups)\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.BatchNorm2d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.relu = nn.ReLU6()\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.conv1(x)\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.relu(x)\n",
        "        return x"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDwkecbBHqSL"
      },
      "source": [
        "class Inverted_Res_Block(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 t , \n",
        "                 stride = (1 , 1)):\n",
        "        super(Inverted_Res_Block , self).__init__()\n",
        "        \n",
        "        self.use_residual = in_channels == out_channels and stride == 1\n",
        "        hidden_dim = in_channels * t\n",
        "        self.conv1 = Conv(in_channels , hidden_dim , kernel_size=(1 , 1) , stride=(1 , 1) , padding=0)\n",
        "        self.conv2 = Conv(hidden_dim , hidden_dim , stride=stride , use_grps=True)\n",
        "        self.conv3 = Conv(hidden_dim , out_channels , kernel_size=(1 , 1) , stride=(1 , 1) , padding=0)\n",
        "    def forward(self , x):\n",
        "        x_ = x.clone()\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        if self.use_residual:\n",
        "            return x + x_\n",
        "        else :\n",
        "            return x"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGVZppEVIpCj"
      },
      "source": [
        "x = torch.randn(2 , 32 , 112 , 112).to(device)\n",
        "inverted_res_block = Inverted_Res_Block(32 , 16 , 6 , stride=2).to(device)\n",
        "z = inverted_res_block(x)\n",
        "z.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptuhkGtBJTHd"
      },
      "source": [
        "config = [\n",
        "          # t , out_channels , repeats , stride\n",
        "          [1 , 16 , 1 , 1] , \n",
        "          [6 , 24 , 1 , 1] , \n",
        "          [6 , 32 , 3 , 2] , \n",
        "          [6 , 64 , 4 , 2] , \n",
        "          [6 , 96 , 3 , 1] , \n",
        "          [6 , 160 , 3 , 2] , \n",
        "          [6 , 320 , 1 , 1] , \n",
        "]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIYFzlogI3gx"
      },
      "source": [
        "class MobileNet_v2(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels_model , \n",
        "                 config = config):\n",
        "        super(MobileNet_v2 , self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        self.layers.append(Conv(3 , 32 , stride=(2 , 2)))\n",
        "        in_channels = 32\n",
        "        for layer in config:\n",
        "            if isinstance(layer , list):\n",
        "                t , out_channels , repeats , stride = layer\n",
        "                for _ in range(repeats):\n",
        "                    self.layers.append(\n",
        "                        Inverted_Res_Block(\n",
        "                            in_channels , \n",
        "                            out_channels , \n",
        "                            t , \n",
        "                            stride\n",
        "                        )\n",
        "                    )\n",
        "                    in_channels = out_channels\n",
        "                    out_channels = out_channels\n",
        "                in_channels = out_channels\n",
        "        \n",
        "        self.adp_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv_last = Conv(in_channels , out_channels_model , kernel_size=(1 , 1) , stride=(1 , 1) , padding=0)\n",
        "\n",
        "    def forward(self , x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        x = self.adp_avg_pool(x)\n",
        "        x = self.conv_last(x)\n",
        "        return x.squeeze(-1).squeeze(-1)        "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg3VRjx9LX_j"
      },
      "source": [
        "x = torch.randn(2 , 3 , 224 , 224).to(device)\n",
        "mobile_net = MobileNet_v2(3 , 1280).to(device)\n",
        "z = mobile_net(x)\n",
        "z.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoQxPn1xLhAJ"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}