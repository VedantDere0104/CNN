{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSPDenseNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaCPdip4lm24"
      },
      "source": [
        "####"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru7LQADRlpSU"
      },
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEFKMnDTlzXy"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D2vF1Ecl3qx"
      },
      "source": [
        "\n",
        "class Conv(nn.Module):\n",
        "    def __init__(self ,\n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 kernel_size = (3 , 3) , \n",
        "                 stride = (1 , 1) , \n",
        "                 padding = 1 , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True ):\n",
        "        super(Conv , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels , \n",
        "                               out_channels ,\n",
        "                               kernel_size , \n",
        "                               stride , \n",
        "                               padding)\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.InstanceNorm2d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.activation = nn.LeakyReLU(0.2)\n",
        "\n",
        "\n",
        "    def forward(self , x):\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.activation(x)\n",
        "        x = self.conv1(x)\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWVCY5Nnl5yZ"
      },
      "source": [
        "\n",
        "class DenseNet_Conv(nn.Module):\n",
        "    def __init__(self, \n",
        "                 in_channels ,\n",
        "                 out_channels):\n",
        "        super(DenseNet_Conv , self).__init__()\n",
        "\n",
        "        self.conv1 = Conv(in_channels , \n",
        "                          in_channels , \n",
        "                          kernel_size=(1 , 1) , \n",
        "                          stride = (1 , 1) , \n",
        "                          padding = 0)\n",
        "        self.conv2 = Conv(in_channels , \n",
        "                          out_channels)\n",
        "        \n",
        "    def forward(self , x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP9hDAWMl76R"
      },
      "source": [
        "class DenseNet_Block(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 repeats , \n",
        "                 k = 12):\n",
        "        super(DenseNet_Block , self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        out_channels_last = 0\n",
        "        in_channels_conv = in_channels // 3\n",
        "        self.remaining_in_channels = in_channels - in_channels_conv\n",
        "\n",
        "        self.in_channels_ = in_channels\n",
        "        self.in_channels_conv_ = in_channels_conv\n",
        "        for r in range(repeats):\n",
        "            #in_channels = in_channels + out_channels_last\n",
        "            out_channels = in_channels_conv + k \n",
        "            #print(in_channels , out_channels)\n",
        "            self.layers.append(DenseNet_Conv(in_channels_conv , \n",
        "                                             out_channels))\n",
        "            \n",
        "            out_channels_last += in_channels_conv\n",
        "            in_channels_conv = out_channels + out_channels_last\n",
        "        #print(out_channels)\n",
        "        self.out_channels = out_channels + self.remaining_in_channels+ out_channels_last\n",
        "\n",
        "        \n",
        "    def _concat(self , x , prev):\n",
        "        for prev_ in prev:\n",
        "            x = torch.cat([x , prev_] , dim=1)\n",
        "        return x\n",
        "\n",
        "    def forward(self , x):\n",
        "        x_cpy = x.clone()\n",
        "        x = x[: , :self.in_channels_conv_ , : , :]\n",
        "        x_ = x_cpy[: , self.in_channels_conv_ : self.in_channels_ , : , :]\n",
        "        #print(x_.shape)\n",
        "        prev = [x]\n",
        "        for layer in self.layers:\n",
        "            #print(x.shape)\n",
        "            x = layer(x)\n",
        "            x = self._concat(x , prev)\n",
        "            prev.append(x)\n",
        "        #print(x.shape , x_.shape)\n",
        "        x = torch.cat([x , x_] , dim=1)\n",
        "        return x "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tigc2fQ2oBv2",
        "outputId": "cb73d423-2718-4f26-c898-35bfc9d127f4"
      },
      "source": [
        "densenet_block = DenseNet_Block(3 , 4).to(device)\n",
        "x = torch.randn(2 , 3 , 112 , 112).to(device)\n",
        "z = densenet_block(x)\n",
        "z.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 112, 112])\n",
            "torch.Size([2, 286, 112, 112]) torch.Size([2, 2, 112, 112])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 288, 112, 112])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ28IcM5mDn5"
      },
      "source": [
        "config = [\n",
        "          #[out_channels , kernel_size , stride , padding]\n",
        "          [512 , (7 , 7) , (2 , 2) , 3] , \n",
        "          ('P' , (3 , 3) , (2 , 2)) ,  # Tuple => (padding , (kernel_size) , (stride))\n",
        "          \n",
        "          6 , # int => DenseNet Block\n",
        "          ('P' , (2 , 2) , (2 , 2)) , \n",
        "\n",
        "          12 , \n",
        "          ('P' , (2 , 2) , (2 , 2)) , \n",
        "\n",
        "          24 , \n",
        "          ('P' , (2 , 2) , (2 , 2)) , \n",
        "\n",
        "          16 , \n",
        "          ('P' , (2 , 2) , (2 , 2)) , \n",
        "]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC08YaafmF_J"
      },
      "source": [
        "class CSPDenseNet(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 config = config):\n",
        "        super(CSPDenseNet , self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        out_channels_list = [128 , 256 , 512 , 1024]\n",
        "        i = 0\n",
        "        for  layer in config:\n",
        "            if isinstance(layer , list):\n",
        "                out_channels , kernel_size , stride , padding = layer\n",
        "                self.layers.append(Conv(in_channels , out_channels , kernel_size , stride , padding))\n",
        "                in_channels = out_channels\n",
        "            elif isinstance(layer , tuple):\n",
        "                kernel_size , stride = layer[1] , layer[2]\n",
        "                self.layers.append(nn.MaxPool2d(kernel_size , stride))\n",
        "            elif isinstance(layer , int):\n",
        "                repeats = layer\n",
        "                a = DenseNet_Block(in_channels , repeats)\n",
        "                self.layers.append(a)\n",
        "                in_channels = a.out_channels\n",
        "                out_channels = out_channels_list[i]\n",
        "                self.layers.append(Conv(in_channels , out_channels , kernel_size=(1 , 1) , stride=(1 , 1) , padding=0))\n",
        "                i += 1\n",
        "                in_channels = out_channels\n",
        "\n",
        "                \n",
        "    def forward(self , x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2vswSTmmIiR"
      },
      "source": [
        "cspdensenet = CSPDenseNet(3).to(device)\n",
        "x = torch.randn(2 , 3 , 112 , 112).to(device)\n",
        "z = cspdensenet(x)\n",
        "print(z.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}