{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet_With_CBAM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndHWzJmzFeG3"
      },
      "source": [
        "####"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nN2KD3xFhVQ"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hplqb7hFiwm"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osjIPL9LFnwz"
      },
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 kernel_size = (3 , 3) , \n",
        "                 stride = (1 , 1) , \n",
        "                 padding = 1 , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True , \n",
        "                 use_dropout = False):\n",
        "        super(Conv , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "        self.use_dropout = use_dropout\n",
        "        self.conv1 = nn.Conv2d(in_channels , \n",
        "                               out_channels , \n",
        "                               kernel_size , \n",
        "                               stride , \n",
        "                               padding)\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.BatchNorm2d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.activation = nn.ReLU(inplace=True)\n",
        "        if self.use_dropout:\n",
        "            self.dropout = nn.Dropout()\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.conv1(x)\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.activation(x)\n",
        "        if self.use_dropout:\n",
        "            x = self.dropout(x)\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4KE62x2GcMQ"
      },
      "source": [
        "class CAM(nn.Module):\n",
        "    ## Channel Attention Module\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 r=1):\n",
        "        super(CAM , self).__init__()\n",
        "\n",
        "        self.adp_max_pool = nn.AdaptiveMaxPool2d(output_size=(1 , 1))\n",
        "        self.adp_avg_pool = nn.AdaptiveAvgPool2d(output_size=(1 , 1))\n",
        "        self.linear = nn.Linear(in_channels , in_channels//r)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self , x):\n",
        "        x_max = self.adp_max_pool(x)\n",
        "        x_avg = self.adp_avg_pool(x)\n",
        "        #print(x_max.shape , x_avg.shape)\n",
        "        x_max = self.linear(x_max.squeeze(-1).squeeze(-1))\n",
        "        x_avg = self.linear(x_avg.squeeze(-1).squeeze(-1))\n",
        "\n",
        "        x = x_max + x_avg\n",
        "        x = self.sigmoid(x)\n",
        "        return x.view(x.shape[0] , x.shape[1] , 1 , 1) \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP1wBXfeITnO"
      },
      "source": [
        "x = torch.randn(2 , 64 , 128 , 128).to(device)\n",
        "cam = CAM(64).to(device)\n",
        "z = cam(x)\n",
        "z.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezJ2uVHOI2ig"
      },
      "source": [
        "class SAM(nn.Module):\n",
        "    ## Spatial Attention Module\n",
        "    def __init__(self , \n",
        "                 in_channels):\n",
        "        super(SAM , self).__init__()\n",
        "\n",
        "        self.conv1 = Conv(in_channels , 1 , kernel_size=(1 , 1) , stride=(1 , 1) , padding=0)\n",
        "\n",
        "        self.conv2 = Conv(1 , in_channels//2)\n",
        "        self.conv3 = Conv(in_channels//2 , 1)\n",
        "    def forward(self , x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        return x        "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69gGIqMeOVnb"
      },
      "source": [
        "x = torch.randn(2 , 512 , 32 , 32).to(device)\n",
        "sam = SAM(512).to(device)\n",
        "z = sam(x)\n",
        "z.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzi8nKjGOjRG"
      },
      "source": [
        "class CBAM(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels):\n",
        "        super(CBAM , self).__init__()\n",
        "\n",
        "        self.sam = SAM(in_channels)\n",
        "        self.cam = CAM(in_channels)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x_ = x.clone()\n",
        "        x = self.cam(x)\n",
        "        x = x_ * x\n",
        "        x = self.sam(x)\n",
        "        x = x_ * x\n",
        "        return x\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLv6d-PzPSpL"
      },
      "source": [
        "x = torch.randn(2 , 32 , 128 , 128).to(device)\n",
        "cbam = CBAM(32).to(device)\n",
        "z = cbam(x)\n",
        "z.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhEoqLdIFztr"
      },
      "source": [
        "class Resnet_Block(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 downsample = False):\n",
        "        super(Resnet_Block , self).__init__()\n",
        "\n",
        "        self.downsample = downsample\n",
        "    \n",
        "        if self.downsample:\n",
        "            self.conv1 = Conv(in_channels , \n",
        "                        in_channels , \n",
        "                        kernel_size=(2 , 2) , \n",
        "                        stride=(2 , 2) ,\n",
        "                        padding = 0)\n",
        "            \n",
        "            self.conv_skip = Conv(in_channels ,\n",
        "                            out_channels ,\n",
        "                            kernel_size = (2 ,2) , \n",
        "                            stride = (2 , 2) , \n",
        "                            padding = 0)\n",
        "        else:    \n",
        "            self.conv1 = Conv(in_channels , \n",
        "                            in_channels , \n",
        "                            kernel_size=(1 , 1) , \n",
        "                            stride=(1 , 1) ,\n",
        "                            padding = 0)\n",
        "            \n",
        "            self.conv_skip = Conv(in_channels ,\n",
        "                              out_channels ,\n",
        "                              kernel_size = (1 , 1) , \n",
        "                              stride = (1 ,1) , \n",
        "                              padding = 0)\n",
        "            \n",
        "        self.conv2 = Conv(in_channels , \n",
        "                          in_channels)\n",
        "        \n",
        "        self.conv3 = Conv(in_channels , \n",
        "                          out_channels , \n",
        "                          kernel_size = (1 , 1) , \n",
        "                          stride = (1 , 1) , \n",
        "                          padding = 0)\n",
        "        \n",
        "        self.cbam = CBAM(out_channels)\n",
        "        \n",
        "    def forward(self , x): \n",
        "        x_ = x.clone()\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.cbam(x)\n",
        "        x_ = self.conv_skip(x_)\n",
        "        x += x_\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10dPpXfOF2Hi"
      },
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels):\n",
        "        super(Linear , self).__init__()\n",
        "        self.linear1 = nn.Linear(in_channels , out_channels)\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdKlJuLJF9z7"
      },
      "source": [
        "class Resnet(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels):\n",
        "        super(Resnet , self).__init__()\n",
        "\n",
        "        self.conv1 = Conv(in_channels , 64 , kernel_size=(7 , 7) , stride=(2 , 2) , padding=3)\n",
        "\n",
        "        self.conv2 = self._make_repeated_blocks(64 , 256 , 3 , downsample = False)\n",
        "        self.conv3 = self._make_repeated_blocks(256 , 512 , 8)\n",
        "        self.conv4 = self._make_repeated_blocks(512 , 1024 , 36)\n",
        "        self.conv5 = self._make_repeated_blocks(1024 , 2048 , 3)\n",
        "        self.linear = Linear(2048 , out_channels)\n",
        "\n",
        "    def _make_repeated_blocks(self , in_channels , out_channels , repeats , downsample = True):\n",
        "        layers = []\n",
        "        for i in range(repeats):\n",
        "            if i == 0 and downsample == True:\n",
        "                layers.append(Resnet_Block(in_channels , out_channels , downsample=downsample))\n",
        "            elif i == 0:\n",
        "                layers.append(Resnet_Block(in_channels , out_channels))\n",
        "            else:\n",
        "                layers.append(Resnet_Block(out_channels , out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.conv1(x)\n",
        "        x = torch.max_pool2d(x , kernel_size = (2 , 2) , stride = (2 , 2))\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = x.view(x.shape[0] , x.shape[1])\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ol-VeG3GBz7"
      },
      "source": [
        "def test():\n",
        "    resnet = Resnet(3 , 1000).to(device)\n",
        "    x = torch.randn(2 , 3 , 224 , 224).to(device)\n",
        "    z = resnet(x)\n",
        "    print(z.shape)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO6GmbX2GEoO"
      },
      "source": [
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV0te_sdGGP-"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}